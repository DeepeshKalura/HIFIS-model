{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Inference Pipeline for HIFIS-RNN-MLP\n",
    "This notebook defines an Azure machine learning pipeline for batch inference and submits the pipeline as an experiment to be run on an Azure virtual machine. It then publishes the pipeline in the workspace and schedules it to be run at a regular interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import azureml.core\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core import Pipeline, PipelineRun\n",
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the workspace and configure its Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n\"round_trip_load_all()\" has been removed, use\n\n  yaml = YAML()\n  yaml.load(...)\n\ninstead of file \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/conda_dependencies.py\", line 131\n\n                self._conda_dependencies = ruamel.yaml.round_trip_load(base_stream)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ws \u001b[38;5;241m=\u001b[39m Workspace\u001b[38;5;241m.\u001b[39mfrom_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ws_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Set workspace's environment\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pip_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHIFIS_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./../requirements.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m env\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mconda_dependencies\u001b[38;5;241m.\u001b[39madd_pip_package(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazureml-core\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m env\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mconda_dependencies\u001b[38;5;241m.\u001b[39madd_pip_package(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msendgrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/environment.py:1069\u001b[0m, in \u001b[0;36mEnvironment.from_pip_requirements\u001b[0;34m(name, file_path)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pip_requirements\u001b[39m(name, file_path):\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an environment object created from a pip requirements file.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m    :param name: The environment name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m    :rtype: azureml.core.environment.Environment\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path) \u001b[38;5;28;01mas\u001b[39;00m req_file:\n\u001b[1;32m   1071\u001b[0m         env\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mconda_dependencies\u001b[38;5;241m.\u001b[39mset_pip_requirements(req_file\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines())\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/environment.py:768\u001b[0m, in \u001b[0;36mEnvironment.__init__\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython \u001b[38;5;241m=\u001b[39m \u001b[43mPythonSection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_skip_defaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_skip_defaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocker \u001b[38;5;241m=\u001b[39m DockerSection(_skip_defaults\u001b[38;5;241m=\u001b[39m_skip_defaults)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark \u001b[38;5;241m=\u001b[39m SparkSection(_skip_defaults\u001b[38;5;241m=\u001b[39m_skip_defaults)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/environment.py:110\u001b[0m, in \u001b[0;36mPythonSection.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m options\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_skip_defaults\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconda_dependencies \u001b[38;5;241m=\u001b[39m \u001b[43mCondaDependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/conda_dependencies.py:131\u001b[0m, in \u001b[0;36mCondaDependencies.__init__\u001b[0;34m(self, conda_dependencies_file_path, _underlying_structure)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m resource_stream(\n\u001b[1;32m    128\u001b[0m         BASE_PROJECT_MODULE,\n\u001b[1;32m    129\u001b[0m         BASE_PROJECT_FILE_RELATIVE_PATH\n\u001b[1;32m    130\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m base_stream:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conda_dependencies \u001b[38;5;241m=\u001b[39m \u001b[43mruamel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_trip_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m         base_stream\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    134\u001b[0m CondaDependencies\u001b[38;5;241m.\u001b[39m_validate_yaml(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conda_dependencies)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ruamel/yaml/main.py:1127\u001b[0m, in \u001b[0;36mround_trip_load\u001b[0;34m(stream, version, preserve_quotes)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround_trip_load\u001b[39m(\n\u001b[1;32m   1118\u001b[0m     stream: StreamTextType,\n\u001b[1;32m   1119\u001b[0m     version: Optional[VersionType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1120\u001b[0m     preserve_quotes: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1121\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03m    Resolve only basic YAML tags.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1127\u001b[0m     \u001b[43merror_deprecation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mround_trip_load_all\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ruamel/yaml/main.py:1037\u001b[0m, in \u001b[0;36merror_deprecation\u001b[0;34m(fun, method, arg, comment)\u001b[0m\n\u001b[1;32m   1035\u001b[0m s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m-> 1037\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(s)\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(s, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n\"round_trip_load_all()\" has been removed, use\n\n  yaml = YAML()\n  yaml.load(...)\n\ninstead of file \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/conda_dependencies.py\", line 131\n\n                self._conda_dependencies = ruamel.yaml.round_trip_load(base_stream)\n\n"
     ]
    }
   ],
   "source": [
    "# Get reference to the workspace\n",
    "ws = Workspace.from_config(\"./ws_config.json\")\n",
    "\n",
    "# Set workspace's environment\n",
    "env = Environment.from_pip_requirements(name = \"HIFIS_env\", file_path = \"./../requirements.txt\")\n",
    "env.python.conda_dependencies.add_pip_package(\"azureml-core\")\n",
    "env.python.conda_dependencies.add_pip_package(\"sendgrid\")\n",
    "env.register(workspace=ws)\n",
    "runconfig = RunConfiguration(conda_dependencies=env.python.conda_dependencies)\n",
    "print(env.python.conda_dependencies.serialize_to_string())\n",
    "\n",
    "# Move AML ignore file to root folder\n",
    "aml_ignore_path = shutil.copy('./.amlignore', './../.amlignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create references to persistent and intermediate data\n",
    "Create DataReference objects that point to our raw data on the blob. Configure a PipelineData object to point to preprocessed data stored on the blob. Pipeline data is intermediate, meaning that it is produced by a step and will be fed as input to a subsequent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blob datastores associated with this workspace\n",
    "hifis_blob_ds = Datastore(ws, name='hifisrnnmlp_ds')\n",
    "raw_data_blob_ds = Datastore(ws, name='hifis_raw_ds')\n",
    "\n",
    "# Create data references to folders on the blobs\n",
    "raw_data_dr = DataReference(\n",
    "    datastore=raw_data_blob_ds,\n",
    "    data_reference_name=\"raw_data\",\n",
    "    path_on_datastore=\"hifis/\")\n",
    "inference_dr = DataReference(\n",
    "    datastore=hifis_blob_ds,\n",
    "    data_reference_name=\"inference\",\n",
    "    path_on_datastore=\"inference/\")\n",
    "\n",
    "# Set up intermediate pipeline data to store preprocessed data and serialized objects needed for inference (e.g. explainer)\n",
    "preprocess_pd = PipelineData(\n",
    "    \"preprocessed_output\",\n",
    "    datastore=hifis_blob_ds,\n",
    "    output_name=\"preprocessed_output\",\n",
    "    output_mode=\"mount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Target\n",
    "Specify and configure the compute target for this workspace. If a compute cluster by the name we specified does not exist, create a new compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "CT_NAME = \"ds12v2-infer\"          # Name of our compute cluster\n",
    "VM_SIZE = \"STANDARD_DS12_V2\"      # Specify the Azure VM for execution of our pipeline\n",
    "MIN_NODES = 0                    # Min number of compute nodes in cluster\n",
    "MAX_NODES = 3                    # Max number of compute nodes in cluster\n",
    "\n",
    "# Set up the compute target for this experiment\n",
    "try:\n",
    "    compute_target = AmlCompute(ws, CT_NAME)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=VM_SIZE, min_nodes=MIN_NODES, max_nodes=MAX_NODES)    \n",
    "    compute_target = ComputeTarget.create(ws, CT_NAME, provisioning_config)  # Create the compute cluster\n",
    "    \n",
    "    # Wait for cluster to be provisioned\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20) \n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")\n",
    "print(\"Compute targets: \", ws.compute_targets)\n",
    "compute_target = ws.compute_targets[CT_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipeline and submit experiment.\n",
    "Define the steps of an Azure machine learning pipeline. Create an Azure Experiment that will run our pipeline. Submit the experiment to the execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing step in the ML pipeline\n",
    "step1 = PythonScriptStep(name=\"preprocess_step\",\n",
    "                         script_name=\"azure/preprocess_step/preprocess_step.py\",\n",
    "                         arguments=[\"--rawdatadir\", raw_data_dr, \"--inferencedir\", inference_dr, \"--preprocessedoutputdir\", \n",
    "                                    preprocess_pd],\n",
    "                         inputs=[raw_data_dr, inference_dr],\n",
    "                         outputs=[preprocess_pd],\n",
    "                         compute_target=compute_target, \n",
    "                         source_directory=\"./../\",\n",
    "                         runconfig=runconfig,\n",
    "                         params={\"PIPELINE\": \"inference\"},\n",
    "                         allow_reuse=False)\n",
    "\n",
    "# Define batch inference step in the ML pipeline\n",
    "step2 = PythonScriptStep(name=\"inference_step\",\n",
    "                         script_name=\"azure/inference_step/inference_step.py\",\n",
    "                         arguments=[\"--preprocessedoutputdir\", preprocess_pd, \"--inferencedir\", inference_dr],\n",
    "                         inputs=[preprocess_pd, inference_dr],\n",
    "                         outputs=[],\n",
    "                         compute_target=compute_target, \n",
    "                         source_directory=\"./../\",\n",
    "                         runconfig=runconfig,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "\n",
    "# Construct the ML pipeline from the steps\n",
    "steps = [step1, step2]\n",
    "inference_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "inference_pipeline.validate()\n",
    "\n",
    "# Define a new experiment and submit a new pipeline run to the compute target.\n",
    "experiment = Experiment(workspace=ws, name='BatchInferenceExperiment_v1')\n",
    "inference_run = experiment.submit(inference_pipeline, regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution\")\n",
    "\n",
    "# Move AML ignore file back to original folder\n",
    "aml_ignore_path = shutil.move(aml_ignore_path, './.amlignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish the pipeline\n",
    "Wait for the pipeline run to finish. Then publish the pipeline. The pipeline will be visible as an endpoint in the Pipelines tab in the workspace on Azure Machine Learning studio. Delete the training compute cluster to prevent further cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the pipeline to finish running.\n",
    "inference_run.wait_for_completion()\n",
    "\n",
    "# Publish the pipeline.\n",
    "published_pipeline = inference_run.publish_pipeline(\n",
    "     name=\"HIFIS-RNN-MLP Inference Pipeline\",\n",
    "     description=\"Azure ML Pipeline that runs model inference on all clients in HIFIS database and computes LIME explanations\",\n",
    "     version=\"1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule the pipeline\n",
    "Schedule the published pipeline to run weekly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1)\n",
    "pipeline_id = \"inference-pipeline\"\n",
    "recurring_schedule = Schedule.create(ws, name=\"WeeklyInferenceSchedule\", \n",
    "                            description=\"Scheduled weekly batch inference\",\n",
    "                            pipeline_id=published_pipeline.id, \n",
    "                            experiment_name=experiment.name, \n",
    "                            recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable scheduled pipelines\n",
    "Disable all scheduled pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules = Schedule.list(ws)\n",
    "for schedule in schedules:\n",
    "    print(schedule)\n",
    "    schedule.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
